#!/usr/bin/env python3

import os
from pathlib import Path
from os.path import join
import asyncio
import fnmatch

import aiohttp
from aiohttp.client_exceptions import InvalidURL
from scrapy.selector import Selector

DIR_URL_DESTINATION = 'url_result'


def replace(doc, https_lines):
    for line in https_lines:
        doc = doc.replace(line['http'], line['https'])
    return doc


async def update(login, password, datas):
    async with aiohttp.ClientSession() as session:
        connection_payload = {
            'id': 'accueil',
            'do': 'login',
            'u': login,
            'p': password
        }
        async with session.post('https://doc.ubuntu-fr.org/accueil?do=login', data=connection_payload):
            pass

        for d in datas:
            print('Editer "%s" ?' % d['path'].replace('.txt', ''))
            
            try:
                async with session.get(d['url']) as r:
                    page = await r.text()
            except InvalidURL:
                print(f'invalid url : {d["url"]}')
                continue

            page_sel = Selector(text=page)
            dokuwiki = page_sel.css('#wiki__text::text').get()
            sectok = page_sel.xpath('//input[@name="sectok"]').attrib['value']
            date = page_sel.xpath('//input[@name="date"]').attrib['value']
            changecheck = page_sel.xpath('//input[@name="changecheck"]').attrib['value']

            payload = {
                'sectok': sectok,
                'date': date,
                'changecheck': changecheck,
                'summary': 'passage de http à https sur les liens externes (détecté et corrigé via le bot wiki-corrector (https://forum.ubuntu-fr.org/viewtopic.php?id=2067892)',
                'do[save]': '',
                'minor': 1,
                'wikitext': replace(dokuwiki, d['https_lines'])
            }

            async with session.post(d['url'], data=payload):
                pass

            # update file
            with open(d['path'], 'w') as f:
                f.write(d['update_warnings'])


def extract_link(line):
    return {
        'http': line[line.find('http://'):line.find(' => ')],
        'https': line[line.find('https://'):]
    }


def get_content(root, _file):
    content = Path(join(root, _file)).read_text(encoding='UTF-8')
    has_https = 'HTTP redirect to HTTPS'
    if not has_https in content:
        return
    lines = content.split('\n')
    https_lines = [extract_link(line) for line in lines if has_https in line]

    return {
        'path': join(root, _file),
        'url': '%s?do=edit' % join(
            'https://doc.ubuntu-fr.org/',
            root.replace(f'{DIR_URL_DESTINATION}', ''),
            _file.replace('.txt', '')
        ),
        'https_lines': https_lines,
        'update_warnings': '\n'.join([line for line in lines if not has_https in line])
    }


def replace_page(login, password, datas):
    asyncio.run(update(login, password, datas))


def walk(login, password):
    datas = []
    for root, _dir, files in os.walk(DIR_URL_DESTINATION):
        for _file in fnmatch.filter(files, '*'):
            d = get_content(root, _file)
            if not d:
                continue
            datas.append(d)
    replace_page(login, password, datas)


if __name__ == '__main__':
    print('Enter login :')
    login = input()
    print('Enter password :')
    password = input()

    #replace_page(
    #    login, password,
    #    [get_content(DIR_URL_DESTINATION, 'abiword.txt')]
    #)
    walk(login, password)
